- Cross Entropy
	- 定义：熵是服从某一特定概率分布事件的理论最小平均编码长度
	- Formula
		- $$ Entropy = - \sum_{i} P(i) \log_{2}P(i)$$
		- $$ H(P) = Entropy = E_{x~P}[-logP(x)] $$
		- $$H(p)=∑xp(x)×L(x) $$
	- https://zhuanlan.zhihu.com/p/149186719